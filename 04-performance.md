---
layout: page
subtitle: Teaching as a Performance Art
---
> ## Learning Objectives
>
> * FIXME
{: .objectives}

FIXME: reference the "Lessons Learned" paper

Teaching is a performing art.
As in music or athletics,
anyone who wants to do it well can draw on an enormous body of experience and research to improve,
but the most important thing is to realize that feedback makes perfect.

Elizabeth Green's book
*[Building a Better Teacher](http://www.amazon.com/Building-Better-Teacher-Teaching-Everyone/dp/0393081591/)*
is a good popular explanation of why.
Its thesis is simple:
most people incorrectly assume that great teachers are born, not made.
From politicians to researchers and teachers themselves,
most of us speak and act as if there's a gene for teaching that someone either has or doesn't.
Most reforms are therefore designed to find and promote those who can and eliminate those who can't.

The problem is,
this assumption is wrong,
so educational reforms based on it (mostly) fail.
Reforms based on changing the culture of teaching would have a greater chance of succeeding,
but as with any cultural change,
they would require the kind of long-term commitment that our society doesn't seem to be very good at.

The book is written as a history of the people who have put that puzzle together in the US,
including Nate Gage and Lee Shulman in the 1960s and 1970s,
Deborah Ball, Magdalene Lampert, and others at Michigan State in the 1980s and 1990s,
and educational entrepreneurs like Doug Lemov today.
Its core begins with a discussion of what James Stigler discovered during a visit to Japan in the early 1990s:

> Some American teachers called their pattern "I, We, You":
> After checking homework,
> teachers announced the day's topic,
> demonstrating a new procedure (I)...
> Then they led the class in trying out a sample problem together (We)...
> Finally, they let students work through similar problems on their own,
> usually by silently making their way through a worksheet (You)...
>
> The Japanese teachers, meanwhile, turned "I, We, You" inside out.
> You might call their version "You, Y'all, We."
> They began not with an > introduction,
> but a single problem that students spent ten or twenty > minutes working through alone (You)...
> While the students worked,
> the teacher wove through the students' desks,
> studying what they came up with and taking notes to remember who had which idea.
> Sometimes the teacher then deployed the students to discuss the problem in small > groups (Y'all).
> Next, the teacher brought them back to the whole group,
> asking students to present their different ideas for how to solve the problem on the chalkboard...
> Finally, the teacher led a discussion,
> guiding students to a shared conclusion (We).

It's tempting to think that this particular teaching technique is Japan's secret sauce:
tempting, but wrong.
The actual key is revealed in the description of Akihiko Takahashi's work.
In 1991,
he visited the United States in a vain attempt to find the classrooms described a decade earlier
in a report by the National Council of Teachers of Mathematics (NCTM).
He couldn't find them.
Instead, he found that American teachers met once a year (if that) to exchange ideas about teaching,
compared to the weekly or even daily meetings he was used to.
What was worse:

> The teachers described lessons they gave and things students said,
> but they did not *see* the practices.
> When it came to observing actual lessons --- watching each other teach ---
> they simply had no opportunity...
> They had, he realized, no *jugyokenkyu*.
> Translated literally as "lesson study",
> *jugyokenkyu* is a bucket of practices that Japanese teachers use to hone their craft,
> from observing each other at work to discussing the lesson afterward
> to studying curriculum materials with colleagues.
> The practice is so pervasive in Japanese schools that it is...effectively invisible.
>
> And here lay the answer to [Akihiko's] puzzle.
> Of course the American teachers' work fell short of the model set by their best thinkers...
> Without *jugyokenkyu*, his own classes would have been equally drab.
> Without *jugyokenkyu*, how could you even teach?

So what does *jugyokenkyu* look like in practice?

> In order to graduate,
> education majors not only had to watch their assigned master teacher work,
> they had to effectively replace him,
> installing themselves in his classroom first as observers and then,
> by the third week, as a wobbly...approximation of the teacher himself.
> It worked like a kind of teaching relay.
> Each trainee took a subject,
> planning five days' worth of lessons... [and then] each took a day.
> To pass the baton,
> you had to teach a day's lesson in every single subject:
> the one you planned and the four you did not...
> and you had to do it right under your master teacher's nose.
> Afterward,
> everyone --- the teacher, the college students, and sometimes even another outside observer ---
> would sit around a formal table to talk about what they saw.
>
> [Trainees] stayed in...class until the students left at 3:00 pm,
> and they didn't leave the school until they'd finished discussing the day's events,
> usually around eight o'clock.
> They talked about what [the master teacher] had done,
> but they spent more time poring over how the students had responded:
> what they wrote in their notes;
> the ideas they came up with, right and wrong;
> the architecture of the group discussion.
> The rest of the night was devoted to planning...
>
> ...By the time he arrived in [the US],
> [Akihiko had] become...famous...
> giving public lessons that attracted hundreds,
> and, in one case, an audience of a thousand.
> He had a seemingly magical effect on children...
> But Akihiko knew he was no virtuoso.
> "It is not only me," he always said...
> "*Many* people."
> After all, it was his mentor...who had taught him the new approach to teaching...
> And [he] had crafted the approach along with the other math teachers
> in [his ward] and beyond.
> Together, the group met regularly to discuss their plans for teaching...
> [At] the end of a discussion,
> they'd invite each other to their classrooms to study the results.
> In retrospect,
> this was the most important lesson:
> not how to give a lesson, but how to study teaching,
> using the cycle of *jugyokenkyu* to put...work under a microscope and improve it.

Putting work under a microscope in order to improve it is commonplace in sports and music.
A professional musician, for example,
will dissect half a dozen different recordings of "Body and Soul" or "Yesterday" before performing it.
They would also expect to get feedback from fellow musicians during practice and after performances.
Many other disciplines work this way too:
the Japanese drew inspiration from [Deming](https://en.wikipedia.org/wiki/W._Edwards_Deming)'s ideas
on continuous improvement in manufacturing,
while the adoption of code review over the last 15 years
has done more to improve everyday programming than any number of books or websites.

But this kind of feedback isn't part of teaching culture in North America.
Here, what happens in the classroom stays in the classroom:
teachers don't watch each other's lessons on a regular basis,
so they can't borrow each other's good ideas.
The result is that *every teacher has to invent teaching on their own*.
They may get lesson plans and assignments from colleagues,
the school board,
a textbook publisher,
or the Internet,
but each teacher has to figure out on their own how to combine that with
the theory they've learned in education school
to deliver an actual lesson in an actual classroom for actual students.

This is a pretty accurate description of what Software Carpentry instructors have to do as well.
Our training course covers the basics of educational psychology and instructional design,
but doesn't walk trainees through our existing material or how to deliver it.
That oversight is completely my fault,
and doubly embarrassing given how many people have asked me to do precisely that.
More importantly,
while instructors may pick ideas up from their fellow teachers at particular bootcamps,
we don't systematically compile and share their experiences.
We don't even really know how much of each topic gets covered in the average bootcamp,
much less how well it works.

Another problem is that there's no longer a "reference implementation" for Software Carpentry.
In January 2013, almost every instructor had taught with Software Carpentry's founder at least once.
That fraction is now closer to a tenth,
and is inevitably going to continue to drop.
The founder's approach to teaching is almost certainly not the best possible,
but at least it was a *single* way that everyone used to have
as a common starting point.

If we were all at the same university,
or even in the same state or province,
we could try fixing all this with some *jugyokenkyu*.
Unfortunately,
what's described in *Building a Better Teacher* depends on
frequent, time-consuming, high-bandwidth interaction,
but our instructors only teach a couple of times a year as a sideline to their real work.
Outside the days they're actually teaching,
they're scattered across six continents,
trying to catch up on all the work they pushed aside to go run a bootcamp.

FIXME: how skill transfer actually works (Fincher)

## In Class

*   Sticky notes
    *   Giving each learner two sticky notes of different colors allows
        instructors to do quick true/false questions as they're teaching. It
        also allows real-time feedback during hands-on work: learners can put
        a green sticky note on their laptop when they have something
        completed, or a red one when they need help.
    *   We also use them as minute cards: before each break, learners take a
        minute to write one thing they've learned on the green sticky note,
        and one thing they found confusing (or too fast or too slow) on the
        red. It only takes a couple of minutes to collate these, and allows
        the instructors to adjust to learners' interests and speed.
*   One up, one down
    *   We frequently also ask for summary feedback at the end of each day.
        The instructors ask the learners to alternately give one positive and
        one negative point about the day, without repeating anything that has
        already been said.  This requirement forces people to say things they
        otherwise might not: once all the "safe" feedback has been given,
        participants will start saying what they really think.
    *   Minute cards are anonymous; the alternating up-and-down feedback is
        not.  Each mode has its strengths and weaknesses, and by providing
        both, we hope to get the best of both worls.
*   Live coding
    *   It's more convincing
    *   It enables instructors to be more responsive to "what if?" questions
    *   It facilitates lateral knowledge transfer (i.e.,
        people learn more than we realized we were teaching by watching how
        instructors do things).
    *   Slows the instructor down
    *   Learners get to see isntructors' mistakes *and how to diagnose and correct them*.
        *   Important because learners will spend most of their time doing this.
    *   It takes a bit of practice for instructors to
        get used to thinking aloud while coding in front of an audience, but
        most report that it is then no more difficult to do than talking off a
        deck of slides.
    *   Many instructors now use two devices when teaching: a laptop plugged
        into the projector for learners to see, and a tablet beside it on
        which they can view their notes and the Etherpad session.
        This seems to be more reliable than
        displaying one virtual desktop while flipping back and forth to
        another.
*   Setup
    *   Learners tell us that it is important to them to leave the workshop
        with their own machine set up to do real work.  We therefore continue
        to teach on all three major platforms (Linux, Mac OS X, and Windows),
        even though it would be simpler to require learners to use just one.
    *   We have experimented with virtual machines (VMs) on learners'
        computers to reduce installation problems, but those introduce
        problems of their own: older or smaller machines simply aren't fast
        enough, and learners often struggle to switch back and forth between
        two different sets of keyboard shortcuts for things like copying and
        pasting.
    *   Some instructors use VPS over SSH or web browser pages instead.  This
        solve the installation issues, but makes us dependent on host
        institutions' WiFi (which can be of highly variable quality), and
        has the issues mentioned above with things like keyboard shortcuts.
*   Collaborative note-taking
    *   We often use [Etherpad](http://etherpad.org) for collaborative
        note-taking and to share snippets of code and small data files with
        learners. (If nothing else, it saves us from having to ask students to
        copy long URLs from the presenter's screen to their computers.) It is
        almost always mentioned positively in post-workshop feedback, and
        several workshop participants have started using it in their own
        teaching.
    *   FIXME: more about emergent properties and quality of notes
*   Pair programming
    *   Pairing is a good practice in real life, and an even better way to
        teach: partners can not only help each other out during the practical,
        but can also clarify each other's misconceptions when the solution is
        presented, and discuss common research interests during breaks. To
        facilitate this, we strongly prefer flat (dinner-style) seating to
        banked (theater-style) seating; this also makes it easier for helpers
        to reach learners who need assistance.

We try to make our teaching as interactive as possible, but we still
don't give learners hands-on exercises as frequently as we should.  We
also don't give them as diverse a range of exercises as we should.
This is simply due to a lack of time: two eight-hour days are as much
as learners' brains can handle, but not nearly enough to give them all
the practice they need.

There is also a constant tension between having students do realistic
exercises drawn from actual scientific workflows, and giving them tasks
that are small and decoupled, so that failures are less likely and don't
have knock-on effects when they occur. This is exacerbated by the
diversity of learners in the typical workshop.

## Pace and Level

The diversity of our learners'
backgrounds and skill levels. No matter what we teach, and how fast or
how slow we go, 20% or more of the room will be lost, and there's a
good chance that a different 20% will be bored.

The obvious solution is to split people by level, but if we ask them
how much they know about particular things, they regularly under- or
over-estimate their knowledge.  We have therefore developed a short
pre-assessment questionnaire that asks them how easily they could do a
small number of specific tasks.  It is useful, in that it gives
instructors some idea of who they're going to be helping, but we have
done nothing to validate the questions themselves, i.e., to ensure
that respondents are interpreting them the same way that we are, or
that their categorization of respondents corresponds in any meaningful
way to actual proficiency.

We have been trying for several years to find the support needed to do
rigorous assessment of this and other aspects of our program, but if
funders are reluctant to invest in training, they are doubly reluctant
to invest in measuring its effects.

FIXME: incorporate more from recent blog posts

## Workshop Operations

FIXME: include more from the workshop operations guide and point at checklists

Starting in January 2015 we began running biweekly debriefing
sessions for instructors who have recently taught workshops, in which
they can discuss what they actually did, how it worked, how the
lessons they actually delivered differed from our templates, what
problems arose, and so on.  Summaries are posted shortly after each
meeting.

### Use What We Teach

We make a point of eating our own cooking, e.g., we use GitHub
for our web site and to plan workshops. Again, this makes us more
credible, and gives instructors hands-on practice with the things
they're going to teach.  Up until a year ago, the (considerable)
downside to this was that it could be difficult for newcomers to
contribute material.  We have simplified our templates and build
procedures considerably to fix this, and will be making more changes
early in 2016 to incorporate further insights.

### Open Lessons

This is an important special case of the previous point. Anyone who
wants to use our lessons can take what we have, make changes, and
offer those back by sending us a pull request on GitHub. This workflow
is foreign to most educators, but allows us to scale and adapt more
quickly and more cheaply than the centralized approaches being taken
by many high-profile online education ventures.

For example, we recently published our core lessons through
[Zenodo](https://zenodo.org/).  The distribution of contributions has
the usual long-tail distribution, but the fact remains that our
lessons have had more contributors than many "massive" and "open"
online courses.

### Software Installation

Third, getting software installed is often harder than using it. This
is a hard enough problem for experienced users, but almost by
definition our audience is *inexperienced*, and our learners don't
(yet) know about system paths, environment variables, the half-dozen
places configuration files can lurk on a modern system, and so
on. Combine that with two versions of Mac OS X, three of Windows, and
two oddball Linux distributions, and it's almost inevitable that every
time we introduce a new tool, it won't work as expected (or at all)
for at least one person in the room. Detailed documentation has not
proven effective: some learners won't read it (despite repeated
prompting), and no matter how detailed it is, it will be
incomprehensible to some, and lacking for others.

### Editors

Editing text should be a minor problem, but if you're standing in
class telling three sets of users, "Now open Notepad++ if you're on
Windows, or Kate if you're on Linux, or TextMate if you're on a Mac,
or whatever you want to use if you're more advanced", and then
demonstrate with whichever you have on your laptop (which looks
different from what half of your learners are sitting in front of),
you wll cause mass confusion.

We therefore still use [Nano](http://www.nano-editor.org/) as an
editor in class, even though none of our instructors use it for real
work.  Arguments over this will probably never end: many people who
are passionate about programming are also passionate (some might say
"zealous") about their favorite editor, and will argue about the
relative merits of various choices at length.

The choice of editor is an example of expert blind spot.  People who
know a subject well often have trouble re-imagining it through novice
eyes, and hence under-estimate how difficult "simple" tasks actually
are for newcomers.  For example, every reasonably experienced user of
the shell knows that an editor can run inside a terminal window, so
that a single fixture on the screen can play multiple roles.  This is
*not* obvious to newcomers, who are frequently confused when
instructors move back and forth between an editor and a regular shell
prompt in a single window.

## Peer Instruction

Clearing up novices' misconceptions is more important than imparting
information.  However, when novices misunderstand something, they can
all misunderstand it differently.  And no matter how good the teacher
is, she can only pitch a lesson at one level at a time.  How can that
be scaled?

The best solution so far is called *peer instruction*.  Originally
developed by Eric Mazur at Harvard, it has been studied extensively in
a wide variety of contexts, including programming.  When it is used,
the basic learning cycle is typically something like this, to be
followed after a short lesson on a single concept:

1.  Give students an MCQ, probing for misconceptions on the topic just
    taught.
2.  Have all the students vote publicly on their answers to the MCQ.
3.  Break the class into groups of 3-4, and have them discuss and debate
    the question within their groups.
4.  Reconvene and have the students vote again.
5.  If necessary, explain the solution to the probelem, have the
    students return to their former groups, and discuss the problem again.

Having students discuss their original answers compels then to clarify
their thinking, which can be enough to call out gaps in reasoning.
Re-polling the class then lets the instructor know if they can move
on, or if further explanation is necessary. A final round of
additional discussion after this explanation then serves to give
another chance for strong students to compile their understanding into
something they can deliver as tutoring to their weaker peers.

FIXME: we don't use PI because it takes people time to learn a new way
to learn, and we don't have that time in our two-day workshops.

## Things You Shouldn't Do

*   Telling learners they are rubbish because they use Excel and/or Word
    don't modularise their code, etc.
*   Repeatedly make digs about Windows and praise Linux, e.g., say that
    the former is for amateurs.
*   Criticize GUI appications (and by implication their users) and
    describe command-line tools as the One True Way.
*   Dive into complex or detailed technical discussion with the one or
    two people in the audience who clearly don't actually need to be
    there.
*   Pretend to know more than you do.  People will actually trust you
    more if you are frank about the limitations of your knowledge, and
    will be more likely to ask questions and seek help.
